{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf9a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tab\\Documents\\Code\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from six import StringIO  \n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import requests\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "import optparse\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "random.seed(1242)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa78d4f",
   "metadata": {},
   "source": [
    "### Testing for Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7154c57",
   "metadata": {},
   "source": [
    "To test for overfitting, we will run the algorithm through another user profile and analyze the results. We will use the profile SimplySweet (user 26149) for this since its favorited animes differ from Zeroskye's profile, allowing us to see how the model performs on varied profile compositions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642d2b5",
   "metadata": {},
   "source": [
    "The favorited animes in this profile are:\n",
    "- 6045: Kimi ni Todoke\n",
    "- 164: Mononoke Hime\n",
    "- 431: Howl no Ugoku Shiro\n",
    "- 202: Wolf's Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b1a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_anime_dataset = pd.read_csv('user_anime_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd5341b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate cosine similarity between two items\n",
    "def calculate_cosine_similarity(item1, item2):\n",
    "    return 1 - cosine(item1, item2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa66fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 most similar users to user 26149 are       Similarity\n",
      "26149          1\n",
      "48735          1\n",
      "31759          1\n",
      "61449    0.67082\n",
      "76012   0.612372.\n",
      "We would recommend the following based on a combination of user-item approach: anime_5114, anime_1, anime_199, anime_1535, anime_9253, anime_30, anime_11061, anime_4181, anime_457, anime_1575. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Select user 26149 (SimplySweet)\n",
    "target_user_id = 26149\n",
    "user_7968 = user_anime_dataset[user_anime_dataset['user_id'] == target_user_id].set_index('user_id')\n",
    "user_7968_animes = user_7968.columns[user_7968.values.flatten() == 1]\n",
    "\n",
    "# Calculate cosine similarity with all users\n",
    "similarities = pd.DataFrame(index=user_anime_dataset['user_id'].unique(), columns=['Similarity'])\n",
    "\n",
    "for index, row in user_anime_dataset.iterrows():\n",
    "    similarity = calculate_cosine_similarity(user_7968.values.flatten(), row.values[1:])\n",
    "    similarities.loc[row['user_id']] = similarity\n",
    "\n",
    "# Find the top 5 most similar users\n",
    "top_5_most_similar = similarities.sort_values(by='Similarity', ascending = False).head(5)\n",
    "\n",
    "# Initialize an empty DataFrame for recommendation scores\n",
    "recommendation_scores = pd.DataFrame(index = user_anime_dataset['user_id'].unique(), columns = user_anime_dataset.columns[1:])\n",
    "\n",
    "# Fill in recommendation scores for each user and anime\n",
    "for index, row in user_anime_dataset.iterrows():\n",
    "    if row['user_id'] == target_user_id:\n",
    "        continue  # Skip the target user\n",
    "    \n",
    "    # Calculate recommendation score using a combination of user and item approach\n",
    "    recommendation_scores.loc[row['user_id']] = row.values[1:] * similarities.loc[row['user_id'], 'Similarity']\n",
    "\n",
    "# Sum recommendation scores across similar users for each anime\n",
    "anime_recommendation_scores = recommendation_scores.sum(axis = 0)\n",
    "\n",
    "# Exclude animes that the target user has already seen\n",
    "anime_recommendation_scores = anime_recommendation_scores[anime_recommendation_scores.index.isin(user_7968_animes) == False]\n",
    "\n",
    "# Sort and get the top 10 recommended animes\n",
    "top_10_recommendations = anime_recommendation_scores.sort_values(ascending = False).head(10)\n",
    "\n",
    "# Convert the variable to a string\n",
    "top_10_recommendations_str = ', '.join(map(str, top_10_recommendations.index))\n",
    "\n",
    "# Display the top 5 most similar users and top 10 recommended animes\n",
    "print(f\"The top 5 most similar users to user {target_user_id} are {top_5_most_similar}.\")\n",
    "print(f\"We would recommend the following based on a combination of user-item approach: {top_10_recommendations_str}. \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffedf1",
   "metadata": {},
   "source": [
    "The recommended animes are:\n",
    "\n",
    "- 5114: Fullmetal Alchemist: Brotherhood\n",
    "- 1: Cowboy Bebop\n",
    "- 199: Sen to Chihiro no Kamikakushi\n",
    "- 1535: Death Note\n",
    "- 9253: Steins;Gate\n",
    "- 30: Offside\n",
    "- 11061: Hunter x Hunter (2011)\n",
    "- 4181: Clannad: After Story\n",
    "- 457: Mushishi\n",
    "- 1575: Code Geass: Hangyaku no Lelouch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
